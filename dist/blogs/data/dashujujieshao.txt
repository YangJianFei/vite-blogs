/*
title:大数据入门：各种大数据技术介绍
date:2022-01-25
keyword:大数据,hadoop,
*/

<div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">

<p>大数据我们都知道hadoop，可是还会各种各样的技术进入我们的视野：Spark，Storm，impala，让我们都反映不过来。为了能够更好的架构大数据项目，这里整理一下，供技术人员，项目经理，架构师选择合适的技术，了解大数据各种技术之间的关系，选择合适的语言。<br>我们可以带着下面问题来阅读本文章：<br><span style="color: rgba(255, 0, 0, 1)">1.hadoop都包含什么技术<br>2.Cloudera公司与hadoop的关系是什么，都有什么产品，产品有什么特性<br>3.Spark与hadoop的关联是什么？<br>4.Storm与hadoop的关联是什么？</span><br><br><img id="aimg_wSJjZ" class="zoom" src="http://www.aboutyun.com/static/image/hrline/4.gif" alt="" width="500" height="35" border="0"><br><br><br><br>hadoop家族<br>创始人：Doug Cutting<br>整个Hadoop家族由以下几个子项目组成：<br><br>Hadoop Common：<br>Hadoop体系最底层的一个模块，为Hadoop各子项目提供各 种工具，如：配置文件和日志操作等。详细可查看<br><a href="http://www.aboutyun.com/thread-6553-1-1.html" target="_blank" rel="noopener">Hadoop技术内幕 深入解析HADOOP COMMON和HDFS架构设计与实现原理大全1-9章</a><br><br>HDFS：<br><br>是Hadoop应用程序中主要的分布式储存系统， HDFS集群包含了一个NameNode（主节点），这个节点负责管理所有文件系统的元数据及存储了真实数据的DataNode（数据节点，可以有很多）。HDFS针对海量数据所设计，所以相比传统文件系统在大批量小文件上的优化，HDFS优化的则是对小批量大型文件的访问和存储。下面为详细资料：<br><a href="http://www.aboutyun.com/thread-6748-1-1.html" target="_blank" rel="noopener">什么是HDFS及HDFS架构设计</a><br><a href="http://www.aboutyun.com/thread-6153-1-1.html" target="_blank" rel="noopener">HDFS+MapReduce+Hive快速入门</a><br><a href="http://www.aboutyun.com/thread-6532-1-1.html" target="_blank" rel="noopener">Hadoop2.2.0中HDFS为何具有高可用性</a><br><a href="http://www.aboutyun.com/thread-6779-1-1.html" target="_blank" rel="noopener">Java创建hdfs文件实例</a><br><br>MapReduce：<br><br>是一个软件框架，用以轻松编写处理海量（TB级）数据的并行应用程序，以可靠和容错的方式连接大型集群中上万个节点（商用硬件）。<br>详细可查看：<br><a href="http://www.aboutyun.com/thread-5541-1-1.html" target="_blank" rel="noopener">Hadoop简介(1):什么是Map/Reduce</a><br><a href="http://www.aboutyun.com/thread-5935-1-1.html" target="_blank" rel="noopener">Hadoop MapReduce基础</a><br><a href="http://www.aboutyun.com/thread-6723-1-1.html" target="_blank" rel="noopener">MapReduce工作原理讲解</a><br><a href="http://www.aboutyun.com/thread-6531-1-1.html" target="_blank" rel="noopener">手把手交你写Mapreduce程序实例并部署在Hadoop2.2.0上运行</a><br><br>Hive：<br><br>Apache Hive是Hadoop的一个数据仓库系统，促进了数据的综述（将结构化的数据文件映射为一张数据库表）、即席查询以及存储在Hadoop兼容系统中的大型数据集分析。Hive提供完整的SQL查询功能——HiveQL语言，同时当使用这个语言表达一个逻辑变得低效和繁琐时，HiveQL还允许传统的Map/Reduce程序员使用自己定制的Mapper和Reducer。hive类似CloudBase，基于hadoop分布式计算平台上的提供data warehouse的sql功能的一套软件。使得存储在hadoop里面的海量数据 的汇总，即席查询简单化。<br>详细可查看：<br><a href="http://www.aboutyun.com/thread-6509-1-1.html" target="_blank" rel="noopener">Hive的起源及详细介绍</a><br><a href="http://www.aboutyun.com/thread-5731-1-1.html" target="_blank" rel="noopener">hive详解视频</a><br><br><br>Pig：<br><br><span style="font-family: Tahoma, Helvetica, simsun, sans-serif">Apache Pig是一个用于大型数据集分析的平台，它包含了一个用于数据分析应用的高级语言以及评估这些应用的基础设施。Pig应用的闪光特性在于它们的结构经得起大量的并行，也就是说让它们支撑起非常大的数据集。Pig的基础设施层包含了产生Map-Reduce任务的编译器。Pig的语言层当前包含了一个原生语言——Pig Latin，开发的初衷是易于编程和保证可扩展性。</span><br>Pig是SQL-like语言，是在MapReduce上构建的一种高级查询语言，把一些运算编译进MapReduce模型的Map和Reduce中，并且用户可以定义自己的功能。Yahoo网格运算部门开发的又一个克隆Google的项目Sawzall。<br>详细可查看：<br><a href="http://www.aboutyun.com/thread-6713-1-1.html" target="_blank" rel="noopener">pig入门简单操作及语法包括支持数据类型、函数、关键字、操作符等</a><br><a href="http://www.aboutyun.com/thread-5617-1-1.html" target="_blank" rel="noopener">hadoop家族Pig和Hive有什么不同？</a><br><br><br><br>HBase：<br><br>Apache HBase是Hadoop数据库，一个分布式、可扩展的大数据存储。它提供了大数据集上随机和实时的读/写访问，并针对了商用服务器集群上的大型表格做出优化——上百亿行，上千万列。其核心是Google Bigtable论文的开源实现，分布式列式存储。就像Bigtable利用GFS（Google File System）提供的分布式数据存储一样，它是Apache Hadoop在HDFS基础上提供的一个类Bigatable。<br>详细可查看：<br><a href="http://www.aboutyun.com/thread-6720-1-1.html" target="_blank" rel="noopener">hbase与传统数据的区别</a><br><a href="http://www.aboutyun.com/thread-6612-1-1.html" target="_blank" rel="noopener">HBASE分布式安装视频下载分享</a><br><br>ZooKeeper：<br><br>Zookeeper是Google的Chubby一个开源的实现。它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、 分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。<br>详细可查看：<br><a href="http://www.aboutyun.com/thread-6628-1-1.html" target="_blank" rel="noopener">什么是Zookeeper，Zookeeper的作用是什么，在Hadoop及hbase中具体作用是什么</a><br><br>Avro：<br><br>Avro是doug cutting主持的RPC项目，有点类似Google的protobuf和Facebook的thrift。avro用来做以后hadoop的RPC，使hadoop的RPC模块通信速度更快、数据结构更紧凑。<br><br><br>Sqoop:<br><span style="font-family: Tahoma, Helvetica, simsun, sans-serif">Sqoop是一个用来将Hadoop和关系型数据库中的数据相互转移的工具，可以将一个关系型数据库中数据导入Hadoop的HDFS中，也可以将HDFS中数据导入关系型数据库中。</span><br>详细可查看：<br><a href="http://www.aboutyun.com/thread-6242-1-1.html" target="_blank" rel="noopener">Sqoop详细介绍包括：sqoop命令，原理，流程</a><br><br>Mahout:<br><br>Apache Mahout是个可扩展的机器学习和数据挖掘库，当前Mahout支持主要的4个用例：<br>推荐挖掘：搜集用户动作并以此给用户推荐可能喜欢的事物。<br>聚集：收集文件并进行相关文件分组。<br>分类：从现有的分类文档中学习，寻找文档中的相似特征，并为无标签的文档进行正确的归类。<br>频繁项集挖掘：将一组项分组，并识别哪些个别项会经常一起出现。<br><br><br>Cassandra：<br><br>Apache Cassandra是一个高性能、可线性扩展、高有效性数据库，可以运行在商用硬件或云基础设施上打造完美的任务关键性数据平台。在横跨数据中心的复制中，Cassandra同类最佳，为用户提供更低的延时以及更可靠的灾难备份。通过log-structured update、反规范化和物化视图的强支持以及强大的内置缓存，Cassandra的数据模型提供了方便的二级索引（column indexe）。<br><br>Chukwa：<br><br>Apache Chukwa是个开源的数据收集系统，用以监视大型分布系统。建立于HDFS和Map/Reduce框架之上，继承了Hadoop的可扩展性和稳定性。Chukwa同样包含了一个灵活和强大的工具包，用以显示、监视和分析结果，以保证数据的使用达到最佳效果。<br><br>Ambari：<br><br>Apache Ambari是一个基于web的工具，用于配置、管理和监视Apache Hadoop集群，支持Hadoop HDFS,、Hadoop MapReduce、Hive、HCatalog,、HBase、ZooKeeper、Oozie、Pig和Sqoop。Ambari同样还提供了集群状况仪表盘，比如heatmaps和查看MapReduce、Pig、Hive应用程序的能力，以友好的用户界面对它们的性能特性进行诊断。<br><br><br><br>HCatalog<br><br>Apache HCatalog是Hadoop建立数据的映射表和存储管理服务，它包括：<br>提供一个共享模式和数据类型机制。<br>提供一个抽象表，这样用户就不需要关注数据存储的方式和地址。<br>为类似Pig、MapReduce及Hive这些数据处理工具提供互操作性。<br><br>------------------------------------------------------------------------------------------------------------------------------------------------<br><br>Chukwa：<br><br>Chukwa是基于Hadoop的大集群监控系统，由yahoo贡献。<br><br><br>------------------------------------------------------------------------------------------------------------------------------------------------<br><br>Cloudera系列产品：<br>创始组织：Cloudera公司<br><span style="font-family: Tahoma, Helvetica, simsun, sans-serif">1.Cloudera Manager:</span><br>有四大功能<br>（1）管理<br>（2）监控<br>（3）诊断<br>（4）集成<br><a href="http://www.aboutyun.com/thread-6807-1-1.html" target="_blank" rel="noopener">Cloudera Manager四大功能</a><br><br><span style="font-family: Tahoma, Helvetica, simsun, sans-serif">2.Cloudera CDH：</span>英文名称：CDH (Cloudera's Distribution, including Apache Hadoop)<br>Cloudera对hadoop做了相应的改变。<br>Cloudera公司的发行版，我们将该版本称为CDH（Cloudera Distribution Hadoop）。<br>详细可以查看<br><a href="http://www.aboutyun.com/thread-6788-1-1.html" target="_blank" rel="noopener">Cloudera Hadoop什么是CDH及CDH版本介绍</a><br><span style="font-family: Tahoma, Helvetica, simsun, sans-serif">相关资料</span><br><a href="http://www.aboutyun.com/thread-6809-1-1.html" target="_blank" rel="noopener">CDH3实战Hadoop(HDFS) , HBase , Zookeeper , Flume , Hive</a><br><a href="http://www.aboutyun.com/thread-6808-1-1.html" target="_blank" rel="noopener">CDH4安装实践HDFS、HBase、Zookeeper、Hive、Oozie、Sqoop</a><br><a href="http://www.aboutyun.com/thread-6789-1-1.html" target="_blank" rel="noopener">Hadoop CDH四种安装方式总结及实例指导</a><br><a href="http://www.aboutyun.com/thread-6739-1-1.html" target="_blank" rel="noopener">hadoop的CDH4及CDH5系列文档下载分享</a><br><br><br><span style="font-family: Tahoma, Helvetica, simsun, sans-serif">3.Cloudera Flume</span><br><span style="font-family: Tahoma, Helvetica, simsun, sans-serif">Flume是Cloudera提供的日志收集系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；</span><br>Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。<br><br><br>Flume最早是Cloudera提供的日志收集系统，目前是Apache下的一个孵化项目，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力 Flume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统，支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。<br>Flume采用了多Master的方式。为了保证配置数据的一致性，Flume[1]引入了ZooKeeper，用于保存配置数据，ZooKeeper本身可保证配置数据的一致性和高可用，另外，在配置数据发生变化时，ZooKeeper可以通知Flume Master节点。Flume Master间使用gossip协议同步数据。<br>详细可查看：<br><a href="http://www.aboutyun.com/thread-6247-1-1.html" target="_blank" rel="noopener">什么是 flume 日志收集，flume的特性</a><br><a href="http://www.aboutyun.com/thread-6844-1-1.html" target="_blank" rel="noopener">什么是 flume 日志收集，flume的原理是什么，flume会遇到什么问题</a><br><br><span style="font-family: Tahoma, Helvetica, simsun, sans-serif">4.Cloudera&nbsp;</span>Impala</p>
<div align="left">Cloudera Impala对你存储在Apache Hadoop在HDFS，HBase的数据提供直接查询互动的SQL。除了像Hive使用相同的统一存储平台，Impala也使用相同的元数据，SQL语法（Hive SQL），ODBC驱动程序和用户界面（Hue Beeswax）。Impala还提供了一个熟悉的面向批量或实时查询和统一平台。</div>
<div align="left">详细可查看：</div>
<p>
<a href="http://www.aboutyun.com/thread-6697-1-1.html" target="_blank" rel="noopener">什么是impala，如何安装使用Impala</a><br><span style="font-family: Tahoma, Helvetica, simsun, sans-serif">5.Cloudera&nbsp;</span>&nbsp;&nbsp;hue<br>Hue是cdh专门的一套web管理器，它包括3个部分hue ui，hue server，hue db。hue提供所有的cdh组件的shell界面的接口。你可以在hue编写mr，查看修改hdfs的文件，管理hive的元数据，运行Sqoop，编写Oozie工作流等大量工作。<br>详细可查看：<br><a href="http://www.aboutyun.com/thread-6846-1-1.html" target="_blank" rel="noopener">cloudera hue安装及Oozie的安装</a><br><a href="http://www.aboutyun.com/thread-6847-1-1.html" target="_blank" rel="noopener">什么是Oozie？Oozie简介</a><br><a href="http://www.aboutyun.com/thread-6848-1-1.html" target="_blank" rel="noopener">Cloudera Hue 使用经验分享，遇到的问题及解决方案</a><br><br><br>------------------------------------------------------------------------------------------------------------------------------------------------<br><br>Spark<br><br>创始组织：加州大学伯克利分校 AMP 实验室 (Algorithms, Machines, and People Lab) 开发<br><br><br>Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。<br><br>Spark 是在 Scala 语言中实现的，它将 Scala 用作其应用程序框架。与 Hadoop 不同，Spark 和 Scala 能够紧密集成，其中的 Scala 可以像操作本地集合对象一样轻松地操作分布式数据集。<br><br>尽管创建 Spark 是为了支持分布式数据集上的迭代作业，但是实际上它是对 Hadoop 的补充，可以在 Hadoo 文件系统中并行运行。通过名为 Mesos 的第三方集群框架可以支持此行为。Spark 由加州大学伯克利分校 AMP 实验室 (Algorithms, Machines, and People Lab) 开发，可用来构建大型的、低延迟的数据分析应用程序。<br><br>可以详细了解<br><a href="http://www.aboutyun.com/thread-6849-1-1.html" target="_blank" rel="noopener">科普Spark，Spark是什么，如何使用Spark（1）</a><br><a href="http://www.aboutyun.com/thread-6850-1-1.html" target="_blank" rel="noopener">科普Spark，Spark核心是什么，如何使用Spark（2）</a><br><a href="http://www.aboutyun.com/thread-6852-1-1.html" target="_blank" rel="noopener">优酷土豆用Spark完善大数据分析</a><br><a href="http://www.aboutyun.com/thread-6851-1-1.html" target="_blank" rel="noopener">Hadoop新成员Hadoop-Cloudera公司将Spark加入Hadoop</a><br><br><br>-----------------------------------------------------------------------------------------------------------------------------------------------<br><br>Storm<br><br>创始人：Twitter<br>Twitter将Storm正式开源了，这是一个分布式的、容错的实时计算系统，它被托管在GitHub上，遵循 Eclipse Public License 1.0。Storm是由BackType开发的实时处理系统，BackType现在已在Twitter麾下。GitHub上的最新版本是Storm 0.5.2，基本是用Clojure写的。<br><br>详细可以了解：<br><a href="http://www.aboutyun.com/thread-6222-1-1.html" target="_blank" rel="noopener">storm入门介绍</a><br><a href="http://www.aboutyun.com/thread-6854-1-1.html" target="_blank" rel="noopener">Storm-0.9.0.1安装部署 指导</a><br><a href="http://www.aboutyun.com/thread-6873-1-1.html" target="_blank" rel="noopener">总体认识storm包括概念，场景，组成</a><br><a href="http://www.aboutyun.com/thread-6858-1-1.html" target="_blank" rel="noopener">大数据架构师：hadoop、Storm改选哪一个？</a><br><a href="http://www.aboutyun.com/thread-6855-1-1.html" target="_blank" rel="noopener">大数据架构：flume-ng+Kafka+Storm+HDFS 实时系统组合</a></p>
</div>